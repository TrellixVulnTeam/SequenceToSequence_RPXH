# Attention Mechanism From Scratch

# Input: Encoder Hidden States
# Output: Weights For Each Encoder State representing 

# Question: How is it differentiable?
# Question: How does it work together during the training loop? (specifically with TF)
# How does it backprop? (specifically with TF)
# How does it fit in the context of the overall model?

def generateAttentionProbs(encoderstates):




	# LSTM cell??

	# run softmax

	# return weighted probs associated with each encoder hidden state?

	return 

